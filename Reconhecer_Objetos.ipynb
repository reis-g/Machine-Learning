{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNto8lMn8KSlzyWusBoZRka",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reis-g/Machine-Learning/blob/main/Reconhecer_Objetos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmA-DdxeUuhC"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python opencv-python-headless\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/Colab Notebooks/Produtos/dataset'\n",
        "\n",
        "# Pré-processamento das imagens\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Carregar modelo pré-treinado\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Construir o modelo\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(len(train_data.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinamento\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "\n",
        "model.save('modelo_recomendacao.keras')\n"
      ],
      "metadata": {
        "id": "12G0wgUzAuaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extração de embeddings\n",
        "embedding_model = Model(inputs=model.input, outputs=model.layers[-3].output)\n",
        "\n",
        "# Gerar embeddings\n",
        "def gerar_embedding(imagem):\n",
        "    imagem = cv2.resize(imagem, (224, 224)) / 255.0\n",
        "    imagem = np.expand_dims(imagem, axis=0)\n",
        "    return embedding_model.predict(imagem)\n"
      ],
      "metadata": {
        "id": "eW72NO23A25x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "\n",
        "# Calcular similaridade\n",
        "def recomendar(imagem_consulta, embeddings, nomes_produtos, top_n=5):\n",
        "    consulta_embedding = gerar_embedding(imagem_consulta)\n",
        "    similaridades = cosine_similarity(consulta_embedding, embeddings)\n",
        "    indices = np.argsort(similaridades[0])[::-1][:top_n]\n",
        "    return [(nomes_produtos[i], similaridades[0][i]) for i in indices]\n",
        "\n",
        "# Simular embeddings armazenados\n",
        "with open('embeddings.pkl', 'rb') as f:\n",
        "    embeddings, nomes_produtos = pickle.load(f)\n",
        "\n",
        "# Recomendação\n",
        "imagem_teste = cv2.imread('/content/drive/My Drive/Colab Notebooks/Produtos/teste.jpg')\n",
        "resultados = recomendar(imagem_teste, embeddings, nomes_produtos)\n",
        "\n",
        "# Resultados\n",
        "for produto, similaridade in resultados:\n",
        "    print(f\"Produto: {produto}, Similaridade: {similaridade:.2f}\")\n"
      ],
      "metadata": {
        "id": "yBqeBqncA7Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar embeddings de todas as imagens no dataset\n",
        "embeddings = []\n",
        "nomes_produtos = []\n",
        "\n",
        "for classe, indice in train_data.class_indices.items():\n",
        "    classe_path = os.path.join(dataset_path, classe)\n",
        "    for imagem_nome in os.listdir(classe_path):\n",
        "        imagem = cv2.imread(os.path.join(classe_path, imagem_nome))\n",
        "        if imagem is not None:\n",
        "            embeddings.append(gerar_embedding(imagem))\n",
        "            nomes_produtos.append(classe)\n",
        "\n",
        "# Salvar embeddings\n",
        "with open('embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump((embeddings, nomes_produtos), f)\n"
      ],
      "metadata": {
        "id": "qHvP-mR7A885"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}